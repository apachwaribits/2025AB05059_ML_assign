{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bIk66yl2slc",
        "outputId": "3f3793ae-a6af-458c-d8cb-174fa2960a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "\n",
            "--- FINAL COMPARISON TABLE FOR README ---\n",
            "      ML Model Name  Accuracy      AUC  Precision   Recall       F1      MCC\n",
            "Logistic_Regression  0.752542 0.869383   0.734083 0.752542 0.736308 0.593230\n",
            "      Decision_Tree  0.716384 0.768441   0.710379 0.716384 0.708616 0.537111\n",
            "                kNN  0.698305 0.791192   0.689086 0.698305 0.687903 0.504966\n",
            "        Naive_Bayes  0.692655 0.801522   0.680850 0.692655 0.679823 0.494250\n",
            "      Random_Forest  0.766102 0.875226   0.750497 0.766102 0.749871 0.616348\n",
            "            XGBoost  0.763842 0.875032   0.754142 0.763842 0.755302 0.613874\n",
            "\n",
            "Success! 'test_data.csv' created for Streamlit upload.\n"
          ]
        }
      ],
      "source": [
        "# 1. Setup\n",
        "!pip install ucimlrepo xgboost\n",
        "import os, pickle, pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score,\n",
        "                             recall_score, f1_score, matthews_corrcoef)\n",
        "\n",
        "# 2. Create directory\n",
        "if not os.path.exists('model'): os.makedirs('model')\n",
        "\n",
        "# 3. Data Prep\n",
        "dataset = fetch_ucirepo(id=697)\n",
        "X, y = dataset.data.features, dataset.data.targets\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y.values.ravel())\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Save transformers for Streamlit app\n",
        "with open('model/scaler.pkl', 'wb') as f: pickle.dump(scaler, f)\n",
        "with open('model/encoder.pkl', 'wb') as f: pickle.dump(le, f)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Train 6 Models\n",
        "models = {\n",
        "    \"Logistic_Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision_Tree\": DecisionTreeClassifier(max_depth=10),\n",
        "    \"kNN\": KNeighborsClassifier(),\n",
        "    \"Naive_Bayes\": GaussianNB(),\n",
        "    \"Random_Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier()\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    with open(f'model/{name}.pkl', 'wb') as f: pickle.dump(model, f)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_prob = model.predict_proba(X_test)\n",
        "        auc = roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob.shape[1] > 2 else roc_auc_score(y_test, y_prob[:, 1])\n",
        "    else:\n",
        "        auc = 0.0\n",
        "\n",
        "    # Calculate 6 required metrics\n",
        "    results.append({\n",
        "        \"ML Model Name\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"AUC\": auc,\n",
        "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "        \"F1\": f1_score(y_test, y_pred, average='weighted'),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "    })\n",
        "\n",
        "# 5. Display Table for README\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n--- FINAL COMPARISON TABLE FOR README ---\")\n",
        "print(df_results.to_string(index=False))\n",
        "\n",
        "# 6. EXPORT TEST CSV FOR STREAMLIT UPLOAD\n",
        "# Use inverse transform to get original values for the CSV\n",
        "test_data_export = pd.DataFrame(scaler.inverse_transform(X_test), columns=X.columns)\n",
        "test_data_export['Target'] = le.inverse_transform(y_test)\n",
        "test_data_export.to_csv('test_data.csv', index=False)\n",
        "print(\"\\nSuccess! 'test_data.csv' created for Streamlit upload.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract high-level metadata for README section b\n",
        "print(\"--- DATASET DESCRIPTION (FOR README) ---\")\n",
        "print(f\"Dataset Name: {dataset.metadata.name}\")\n",
        "print(f\"Problem Type: {dataset.metadata.additional_info.get('variable_info', 'Classification')}\")\n",
        "print(f\"Number of Instances: {dataset.data.features.shape[0]}\")\n",
        "print(f\"Number of Features: {dataset.data.features.shape[1]}\")\n",
        "print(f\"Target Variable: {dataset.data.targets.columns[0]}\")\n",
        "print(f\"Class Distribution:\\n{y.value_counts()}\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTLGdkHq4jdS",
        "outputId": "ca5d4a50-5dd6-48aa-847b-4bb236460792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DATASET DESCRIPTION (FOR README) ---\n",
            "Dataset Name: Predict Students' Dropout and Academic Success\n",
            "Problem Type: None\n",
            "Number of Instances: 4424\n",
            "Number of Features: 36\n",
            "Target Variable: Target\n",
            "Class Distribution:\n",
            "Target  \n",
            "Graduate    2209\n",
            "Dropout     1421\n",
            "Enrolled     794\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}